There are a number of concepts which are fundamental to any discussion of \gls{qm}, 
    but are likely to be known to most readers, and are therefore cumbersome to include in the main body of the thesis. 
We include them here for completeness\footnotemark. 
\footnotetext{Much of this description is reproduced from my undergraduate thesis \cite{flynn2015mathematical}.}

\section{Linear algebra}\label{sec:linear_algebra}
Here we review the language of linear algebra and summarise the basic mathematical techniques used throughout this thesis.
We will briefly recall some definitions for reference. 

\begin{table}[H]
    \centering
    \begin{tabular}{lr}
        \hline 
        Definition of & Representation \\
        \hline 
        Vector (or \textit{ket})     & $\ket{\psi} $  \\
        Dual Vector (or \textit{bra}) & $\bra{\psi}  $ \\
        Tensor Product & $\ket{\psi} \otimes \ket{\phi}$ \\
        Complex conjugate & $\ket{\psi^{*}}$ \\
        Transpose & $\ket{\psi}^T $\\
        Adjoint & $\ket{\psi}^{\dag}  = (\ket{\psi}^{*})^{T}$\\
        \hline 
    \end{tabular}
    \caption[Linear algebra defintions]{Linear algebra definitions.}
    \label{table:linear_algebra}
\end{table}
The dual vector of a vector, or \emph{ket} $\ket{\psi}$, is given by its \emph{bra},  $\bra{\psi} = \ket{\psi}^{\dag}$. 

The \textit{adjoint} of a matrix replaces each matrix element with its own complex conjugate, and then switches its columns with rows.
    \begin{equation}
    M^{\dag} = \begin{pmatrix}
    M_{0,0} & M_{0,1} \\ M_{1,0} & M_{1,1} \end{pmatrix}  ^{\dag} = 
    \begin{pmatrix}
    M_{0,0}^* & M_{0,1}^* \\ M_{1,0}^* & M_{1,1}^* \end{pmatrix} ^T = 
    \begin{pmatrix}
    M_{0,0}^* & M_{1,0}^* \\ M_{0,1}^* & M_{1,1}^* \end{pmatrix}.
    \end{equation}
The \textit{inner product} of two vectors, $\ket{\psi} = \icol{\psi_1 \\ \psi_2 \\ \vdots \\ \psi_n}$ and $\ket{\phi}= \icol{\phi_1 \\ \phi_2 \\ \vdots \\ \phi_n }$ is given by 

    \begin{equation}
    \braket{\phi | \psi} = (\ket{\phi}^{\dag})\ket{\psi}
    = (\phi_1^* \ \phi_2^* \ \hdots \ \phi_n^*) \icol{\psi_1 \\ \psi_2 \\ \vdots \\ \psi_n}
    = \phi_1^* \psi_1 + \phi_2^* \psi_2 + \dots + \phi_n^* \psi_n.
    \end{equation}

$\ket{\psi}_i, \ket{\phi}_i$ are complex numbers, and therefore the above is simply a sum of products of complex numbers. 
The inner product is often called the \emph{scalar product}, which is in general complex.

\section{Postulates of \glsentrylong{qm}}\label{sec:postulates}

There are numerous statements of the postulates of quantum mechanics. 
Each version of the statements aims to achieve the same foundation, so we endeavour to explain them in the simplest terms. 

\begin{postulate}
\item \label{postulate:conservative_force_field} 
    Every moving particle in a conservative force field has an associated wave-function, $\ket{\psi}$. 
    From this wave-function, it is possible to determine all physical information about the system. 
\item \label{postulate:eigenvalues} 
    All particles have physical properties called observables (denoted \gls{q}). 
    In order to determine a value, \gls{q}, for a particular observable, there is an associated \emph{operator} $\hat{Q}$, which, 
        when acting on the particles wavefunction, yields the value times the wavefunction. 
    The observable \gls{q} is then the eigenvalue of the operator $\hat{Q}$.
    \begin{equation}
    \hat{Q} \ket{\psi} = q | \psi \rangle
    \end{equation}
\item \label{postulate:hermiticity}
    Any such operator  $\hat{Q}$ is Hermitian
    \begin{equation}
        \hat{Q}^\dag = \hat{Q}
    \end{equation}
\item \label{postulate:eigenfunction}
    The set of eigenfunctions for any operator $\hat{Q}$ forms a complete set of linearly independent functions.
\item \label{postulate:expectation_values}
    For a system with wavefunction $ | \psi \rangle$, the expectation value of an observable \gls{q}  with respect to an operator $\hat{Q}$ is  denoted by $\la q \ra$ and is given by 
    \begin{equation}
    \la q \ra = \langle \psi | \hat{Q} | \psi \rangle
    \end{equation}
\item \label{postulate:schrodinger_eqn}
    The time evolution of $ | \psi \rangle$ is given by the time dependent \emph{Schrodinger Equation}
    \begin{equation}
    i \hbar \frac{\partial \psi}{\partial t} = \hat{H} \psi,
    \end{equation}
    where $\hat{H}$ is the system's Hamiltonian.
\end{postulate}
 
Using these building blocks, we can begin to construct a language to describe quantum systems. 

\section{States}\label{sec:states}
An orthonormal basis consists of vectors of unit length which do not overlap, 
    e.g. $\ket{x_1} = \icol{1 \\ 0 }, \ket{x_2} = \icol{0 \\ 1} \Rightarrow \braket{x_1 | x_2} = 0$. 
In general, if $ \{ \ket{x} \} $ are the eigenstates of a system, then the system can be written as some state vector, $\ket{\psi}$, 
    in general a superposition over the basis-vectors: 

\begin{subequations}
    \begin{equation}\label{apdx_state_vector}
        \ket{\psi} = \sum\limits_{x} a_x |x \rangle 
    \end{equation}
    \begin{equation}\label{vector_norm}
        \textrm{subject to} \ \ \ \sum\limits_{x} |a_x|^2 =1, \ \ \ a_x \in \mathbb{C}.
    \end{equation}
\end{subequations}


The \emph{state space} of a physical system (classical or quantum) is then the set of all possible states the system can exist in, 
    i.e the set of all possible values for $\ket{\psi}$ such that \cref{vector_norm} are satisfied. 
\par 

For example, photons can be polarised horizontally ($\leftrightarrow$) or vertically ($\updownarrow$);
    take those two conditions as observable states to define the eigenstates of a two-level system, 
    so we can designate the photon as a qubit. 
Then we can map the two states to a 2-dimensional, $x\text{-}y$ plane:   
    a general vector on such a plane can be represented by a vector with coordinates $\icol{x \\ y}$. 
These polarisations can then be thought of as standard basis vectors in linear algebra. 
Denote $\leftrightarrow$ as the eigenstate $\ket{0} $ and $\updownarrow$ as $ \ket{1} $
\begin{subequations}
    \begin{equation}
        \ket{\leftrightarrow} = \ket{0} = \icol{1\\0} \ \ \ \ \ \  \text{A unit vector along x-axis}
    \end{equation}
    \begin{equation}
        \ket{\updownarrow} = \ \ket{1} = \icol{0\\1} \ \ \ \ \ \ \text{ A unit vector along y-axis}
    \end{equation}        
\end{subequations}

Now, in relation to the concept of superposition, 
    we can consider, for example, a photon in an even superposition of the vertical and horizontal polarisations, evenly splitting the two basis vectors. 
As such, we would require that, upon measurement, it is equally likely that the photon will \emph{collapse} into the polarised state along $x$ as it is to collapse along $y$. 
That is, we want $ \Pr(\updownarrow) = \Pr(\leftrightarrow) $ so assign equal modulus amplitudes to the two possibilities: 
    \begin{equation}
        \ket{\psi} = a \ket{\leftrightarrow} + b \ket{\updownarrow}, \ \ \ \text{with} \ \ \ \Pr(\updownarrow) = \Pr(\leftrightarrow) \Rightarrow |a|^2 = |b|^2 
    \end{equation}
We consider here a particular case, due to the significance of the resultant basis, where $\leftrightarrow$-polarisation and $\updownarrow$-polarisation have real amplitudes $a,b \in \mathbb{R}$.

\begin{equation}
    \begin{split}
        \Rightarrow a = \pm b \ \ \  & \text{but also} \ \ \ |a|^2 + |b|^2 = 1  
        \\ 
        \Rightarrow \ \ \ a = \frac{1}{\sqrt{2}} \ \ \ &; \ \ \ b = \pm \frac{1}{\sqrt{2}}            
        \\ 
        \Rightarrow \ket{\psi} &= \frac{1}{\sqrt{2}} \ket{\leftrightarrow} \pm \frac{1}{\sqrt{2}} \ket{\updownarrow} 
        \\
        \Rightarrow \ket{\psi} &= \frac{1}{\sqrt{2}} \ket{0} \pm \frac{1}{\sqrt{2}} \ket{1}
    \end{split}
\end{equation} 

These particular superpositions are of significance:
\begin{subequations}
    \begin{equation}
        \ket{+}  = \frac{1}{\sqrt{2}} \left( \ket{0} + \ket{1} \right)
    \end{equation}
    \begin{equation}
        |-\rangle  = \frac{1}{\sqrt{2}} \left(\ket{0} - \ket{1}\right)
    \end{equation}            
\end{subequations}
This is called the Hadamard basis: it is an equally valid vector space as the standard basis which is spanned by $\icol{1\\0}, \icol{0\\1}$, 
    as it is simply a rotation of the standard basis. 
\par 

\subsection{Mulitpartite systems}\label{sec:multipartite}
In reality, we often deal with systems of multiple particles, represented by multiple qubits. 
Mathematically, we consider the state vector of a system containing $n$ qubits as being the tensor product of the $n$ qubits' individual state vectors\footnotemark.
\footnotetext{We will later discuss entangled states, which can not be described thus.} 
For instance, suppose a 2-qubit system, $\ket{\psi}$ consisting of two independent qubits $\ket{\psi_A}$ and $\ket{\psi_B}$: 
\begin{equation}\label{two_qubit_state}
    \ket{\psi}  = \ket{\psi_A} \ket{\psi_B} = \ket{\psi_A \psi_B} = \ket{\psi_A} \otimes \ket{\psi_B}.
\end{equation}

Consider first a simple system of 2 qubits. Measuring in the standard basis, these qubits will have to collapse in to one of the basis states $|0,0 \rangle, |0,1 \rangle, |1,0\rangle, |1,1\rangle $. Thus, for such a 2-qubit system, we have the general superposition
$$ \ket{\psi} = \alpha_{0,0} |0,0 \rangle + \alpha_{0,1}|0,1 \rangle + \alpha_{1,0} |1,0\rangle +\alpha_{1,1} |1,1\rangle. $$ 
where $\alpha_{i,j}$ is the amplitude for measuring the system as the state $|i,j\rangle $. 
This is perfectly analogous to a classical 2-bit system necessarily occupying one of the four possibilities $\left\{ (0,0), (0,1), (1,0), (1,1) \right\}$.

Hence, for example, if we wanted to concoct a two-qubit system composed of one qubit in the state $|+\rangle$ and one in $|-\rangle$

\begin{equation}
    \begin{split}
    \ket{\psi} &= |+\rangle \otimes |-\rangle 
    \\ \ket{\psi} &=  \frac{1}{\sqrt{2}} \left( \ket{0} + \ket{1} \right) \otimes  \frac{1}{\sqrt{2}} \left( \ket{0} - \ket{1} \right)
    \\ &= \frac{1}{2} \left[ \ket{00} - \ket{01} + \ket{10} - \ket{11} \right] 
    \\ &= \frac{1}{2} \left[ \icol{1\\0} \otimes \icol{1\\0} - \icol{1\\0} \otimes \icol{0\\1} + \icol{0\\1} \otimes \icol{1\\0} - \icol{0\\1} \otimes \icol{0\\1} \right]
    \\ &= \frac{1}{2} \left[ \icol{1\\0\\0\\0} - \icol{0\\1\\0\\0} + \icol{0\\0\\1\\0} - \icol{0\\0\\0\\1} \right].
    \\ \Rightarrow \ket{\psi} &= \frac{1}{2} \icol{1\\-1\\-1\\1} 
    \end{split}
\end{equation}

That is, the two qubit system -- and indeed any two qubit system -- is given by a linear combination of the four basis vectors
\begin{equation}
    \left\{ \ket{00}, \ket{01}, \ket{10}, \ket{11} \right\} 
    = \left\{ \icol{1\\0\\0\\0}, \ \icol{0\\1\\0\\0}, \ \icol{0\\0\\1\\0}, \  \icol{0\\0\\0\\1} \right\}.
\end{equation}
We can notice that a single qubit system can be described by a linear combination of two basis vectors, 
    and that a two qubit system requires four basis vectors to describe it. 
In general we can say that an $n$-qubit system is represented by a linear combination of $2^n$ basis vectors. 

\subsection{Registers}
A \textit{register} is generally the name given to an array of controllable quantum systems; here we invoke it to mean a system of multiple qubits, specifically a subset of the total number of available qubits. 
For example, a register of ten qubits can be denoted $\ket{x[10]}$, and we can think of the system as a register of six qubits together with a register of three and another register of one qubit. 
$$ \ket{x[10]} = \ket{x_1[6]} \otimes \ket{x_2[3]} \otimes \ket{x_3[1]} $$


\section{Entanglement}\label{sec:entanglement}
Another unique property of quantum systems is that of \emph{entanglement}: 
    when two or more particles interact in such a way that their individual quantum states can not be described independent of the other particles. 
A quantum state then exists for the system as a whole instead. 
Mathematically, we consider such entangled states as those whose state can not be expressed as a tensor product of the states of the individual qubits it's composed of: they are dependent upon the other. 
\par
To understand what we mean by this dependence, consider a counter-example. 
Consider the Bell state,
\begin{equation}
    \ket{\Phi^{+}} = \frac{1}{\sqrt{2}} \left( \ket{00} + \ket{11} \right),
\end{equation}
if we measure this state, we expect that it will be observed in either eigenstate $\ket{00} $ or $ \ket{11}$, 
    with equal probability due to their amplitudes' equal magnitudes. 
The bases for this state are simply the standard bases, $\ket{0}$ and $\ket{1}$. 
Thus, according to our previous definition of systems of multiple qubits, we would say this state can be given as a combination of two states, like \cref{two_qubit_state}, 

\begin{equation}
    \begin{split}
        \ket{\Phi^{+}} &= \ket{\psi_1} \otimes \ket{\psi_2} 
        \\ &=  \left( a_1 \ket{0} + b_1 \ket{1} \right) \otimes \left( a_2 \ket{0} + b_2 \ket{1} \right)
        \\ &= a_1a_2 \ket{00} + a_1b_2 \ket{01} + b_1a_2 \ket{10} + b_1b_2\ket{11} 
    \end{split}
\end{equation}
However we require $\ket{\Phi^{+}} = \frac{1}{\sqrt{2}} \left( \ket{00} + \ket{11} \right) $, 
    which would imply $a_1b_2 = 0$ and $b_1a_2 = 0$. 
These imply that either $a_1 =0$ or $b_2=0$, and also that $b_1=0$ or $a_2$=0, which are obviously invalid since we require that $a_1a_2 = b_1b_2 = \frac{1}{\sqrt{2}} $. 
Thus, we cannot express $ |\Phi^+ \ra=  \ket{\psi_1} \otimes \ket{\psi_2} $;
    this inability to describe the first and second qubits independently from each other is termed \emph{entanglement}. 

\section{Unitary Transformations}\label{sec:unitary}
A fundamental concept in quantum mechanics is that of performing transformations on states. 
\emph{Quantum transformations}, or \emph{quantum operators}, map a quantum state into a new state within the same Hilbert space. 
There are certain restrictions on a physically possible quantum transformation: in order that $U$ is a valid transformation acting on some superposition $\ket{\psi} = a_1\ket{\psi_1} + a_2 \ket{\psi_2} + \dots a_k|\psi_k\rangle $, $U$ must be linear 
\begin{equation}
    U (  a_1\ket{\psi_1} + a_2 \ket{\psi_2} + \dots a_k|\psi_k\rangle ) =  a_1 (U\ket{\psi_1}) + a_2 (U\ket{\psi_2}) + \dots + a_k (U|\psi_k\rangle).
\end{equation}

% It is also necessary that the order of measurement and transformation do not affect the system: to obtain $|\psi_0\rangle$ with probability $P_0$, 
    % it should be equally valid to first apply $U$ to $\ket{\psi}$ and then measuring, as it is to first measure and then transform the result. %\todo{Does this make any sense?}

To fulfil these properties, we require that $U$ \emph{preserve the inner product}:
$$ \langle \psi_0 | U^{\dag}U | \psi \rangle = \langle \psi_0 | \psi \rangle. $$

That is, we require that any such transformation be \emph{unitary}:

\begin{equation}  \label{unitary condition}
UU^{\dag} = I \\
\Rightarrow U^{\dag} = U^{-1}
\end{equation}

Unitarity is a sufficient condition to describe any valid quantum operation: any quantum transformation can be described by a unitary transformation, 
    and any unitary transformation corresponds to a physically implementable quantum transformation. %\todo{is this too wordy?}

Then, if $U_1$ is a unitary transformation that acts on the space $\mathcal{H}_1$ and $U_2$ acts on $\mathcal{H}_2$, the product of the two unitary transformations is also unitary. 
The tensor product $U_1 \otimes U_2$ acts on the space $\mathcal{H}_1 \otimes \mathcal{H}_2$. 
So, then, supposing a system of two separable qubits, $\ket{\psi_1} $ and $\ket{\psi_2} $ where we wish to act on $\ket{\psi_1} $ with operator $U_1$ and on $\ket{\psi_2} $ with $U_2$, 
    we perform it as
\begin{equation}
    \left( U_1 \otimes U_2 \right) \left(\ket{\psi_1} \otimes \ket{\psi_2} \right) = \left(U_1\ket{\psi_1}\right) \otimes \left(U_2 \ket{\psi_2}\right).
\end{equation}

\section{Dirac Notation}\label{sec:dirac_notation}
In keeping with standard practice, we employ \emph{Dirac notation} throughout this thesis. 
Vectors are denoted by \emph{kets} of the form $|a\rangle$. 
For example, the standard basis is represented by, 
\begin{equation}
    \begin{split}
    \ket{x} =  \ket{0} &= \icol{1\\0};
    \\ \ket{y} = \ket{1} &= \icol{0\\1}.
    \end{split}
\end{equation}
 
We saw in \cref{table:linear_algebra} that for every such ket, $\ket{\psi}$, there exists a \textit{dual vector}: 
    its complex conjugate transpose, called the \emph{bra} of such a vector, denoted $\bra{\psi}$. 
That is,
\begin{equation}
    \begin{split}
        \bra{\psi}^{\dag} &= \ket{\psi},
        \\ \ket{\psi} ^{\dag} &= \bra{\psi}.
    \end{split}
\end{equation}
\begin{equation}
    \ket{\psi} = \icol{\psi_1 \\ \psi_2 \\ \vdots \\ \psi_n} 
    \Rightarrow \bra{\psi}  = \irow{\psi_1^{*} & \psi_2^{*} & \dots & \psi_n^{*}}.
\end{equation}

Then if we have two vectors $\ket{\psi} $ and $\ket{\phi}$, their \emph{inner product} is given as $ \braket{\psi | \phi}  = \braket{ \phi | \psi} $. 

\begin{equation}
    \begin{split}
        \ket{\psi} = \icol{\psi_1 \\ \psi_2 \\ \psi_3 \\ \vdots \\ \psi_n} \ \ \ &; \ \ \ \ket{\phi} = \icol{\phi_1 \\ \phi_2 \\\phi_3 \\ \vdots \\ \phi_n} 
        \\ \Rightarrow \bra{\phi} &= \irow{\phi_1^{*} & \phi_2^{*} & \phi_3^{*} & \dots & \phi_n^{*}}
        \\ \Rightarrow \bra{\phi} \ket{\psi} &= \irow{\phi_1^{*} & \phi_2^{*} & \phi_3^{*} & \dots & \phi_n^{*}} \icol{\psi_1 \\ \psi_2 \\ \psi_3 \\ \vdots \\ \psi_n}
        \\ \Rightarrow \bra{\phi} \ket{\psi} &= \phi_1^{*} \psi_1  +  \phi_2^{*} \psi_2 +  \phi_3^{*} \psi_3 + \dots + \phi_n^{*} \psi_n 
    \end{split}
\end{equation}

\begin{example}
    \begin{equation}
        \begin{split}
            \ket{\psi} = \icol{1 \\ 2 \\ 3} \ \ \ &; \ \ \ket{\phi} = \icol{4\\5\\6} 
            \\ \Rightarrow \bra{\phi} \ket{\psi} &= \irow{4 & 5 & 6} \icol{1\\2\\3}
            \\ &= (4)(1) + (5)(2) +(6)(3) = 32
        \end{split}
    \end{equation}

\end{example}

Similarly, their \emph{outer product} is given as $\ket{\phi} \bra{\psi} $. 
Multiplying a column vector by a row vector thus gives a matrix. 
Matrices generated by a outer products then define operators: 
    
\begin{example}
    \begin{equation}
    \icol{1 \\2}  \irow{3 &4 } = 
        \begin{pmatrix}
            3 & 4  \\
            6 & 8 
        \end{pmatrix}
    \end{equation}
\end{example}

Then we can say, for $\ket{0} = \icol{1\\0} $ and $\ket{1} = \icol{0\\1} $
\begin{subequations}

\begin{equation}
\ket{0} \bra{0} = \begin{pmatrix}
  1 & 0  \\
  0 & 0 
  \end{pmatrix};
\end{equation}


\begin{equation}
\ket{0} \bra{1} = \begin{pmatrix}
  0 & 1  \\
  0 & 0 
  \end{pmatrix};
\end{equation}

\begin{equation}
\ket{1} \bra{0} = \begin{pmatrix}
  0 & 0  \\
  1 & 0 
  \end{pmatrix};
\end{equation}
\qquad
\begin{equation}
\ket{1} \bra{1} = \begin{pmatrix}
  0 & 0  \\
  0 & 1 
  \end{pmatrix}.
\end{equation}

\end{subequations}


And so any 2-dimensional linear transformation in the standard basis $\ket{0}, \ket{1}$ can be given as a sum
\begin{equation}
\begin{pmatrix}
  a & b  \\
  c & d 
  \end{pmatrix} \\
= a \ket{0} \la 0| + b \ket{0} \bra{1} + c \ket{1} \bra{0} + d\ket{1} \bra{1}.
\end{equation}
\\
This is a common method of representing operators as outer products of vectors.
A transformation that \emph{exchanges} a particle between two states, say $\ket{0} \leftrightarrow \ket{1}$ is given by the operation 
$$ \hat{Q}: \begin{cases} \ket{0} \rightarrow \ket{1} \\ \ket{1} \rightarrow \ket{0} \end{cases} $$
Which is equivalent to the outer product representation
$$ \hat{Q} = \ket{0} \bra{1} + \ket{1} \la0|. $$
For clarity, here we will prove this operation


\begin{example}
$$  \hat{Q} = \ket{0} \bra{1} + \ket{1} \la0| $$
 $$ = \icol{1\\0} \icol{0\\1} + \icol{0\\1}\icol{1\\0} $$
 $$ = \begin{pmatrix}
 0 & 1 \\
 0 & 0 \end{pmatrix}  + 
 \begin{pmatrix}
 0&0 \\ 1 &0 
 \end{pmatrix} $$
 $$
 = 
 \begin{pmatrix}
 0&1 \\ 
 1&0
 \end{pmatrix} $$
 
 So then, acting on $\ket{0}$ and $\ket{1}$ gives
 $$ \hat{Q}\ket{0} = \begin{pmatrix} 0&1\\1&0 \end{pmatrix} \icol{1\\0} = \icol{0\\1} = \ket{1} $$
 $$ \hat{Q}\ket{1} = \begin{pmatrix} 0&1\\1&0 \end{pmatrix} \icol{0\\1} = \icol{1\\0} = \ket{0} $$
\end{example}
To demonstrate how Dirac notation simplifies this:
$$ \hat{Q}\ket{0} = (\ket{0} \bra{1} + \ket{1} \la0|) \ket{0} $$
$$ = \ket{0} \bra{1} \ket{0} + \ket{1} \braket{0|0} $$
$$ = \ket{0} \braket{ 1 | 0} + \ket{1} \braket{0 | 0} $$
Then, since $\ket{0}$ and $\ket{1}$ are orthogonal basis, their inner product is $0$ and the inner product of a vector with itself is $1$, 
    i.e. $\braket{1|1} = \braket{0|0} = 1, \braket{0|1} = \braket{1|0} =0$. 
    So,
\begin{equation}
    \begin{split}
    \hat{Q}\ket{0} = \ket{0} (0) + \ket{1}(1) 
    \\ \Rightarrow \hat{Q}\ket{0} = \ket{1} 
    \end{split}
\end{equation}
And similarly for $\hat{Q}\ket{1}$. 
This simple example then shows why Dirac notation can significantly simplify calculations across quantum mechanics, 
    compared to standard matrix and vector notation. 
    To see this more clearly, we will examine a simple 2-qubit state under such operations. 
    The method generalises to operating on two or more qubits generically: 
    we can define any operator which acts on two qubits as a sum of outer products of the basis vectors $ \ket{00}, \ket{01}, \ket{10} \ \text{and} \ \ket{11}$. 
We can similarly define any operator which acts on an $n$ qubit state as a linear combination of the $2^n$ basis states generated by the $n$ qubits. 

\begin{example}
    To define a transformation that will exchange basis vectors $\ket{00}$ and $\ket{11}$, 
        while leaving $\ket{01}$ and $\ket{10}$ unchanged (ie exchanging $\ket{01} \leftrightarrow \ket{01}, \ket{10} \leftrightarrow \ket{10} $) 
        we define an operator
    \begin{equation}
        \hat{Q} = \ket{00} \bra{11} + \ket{11} \bra{00} + |10 \ra \bra{10} + \ket{01} \la 01| 
    \end{equation}
    Then, using matrix calculations this would require separately calculating the four outer products in the above sum and adding them to find a $4\times4$ matrix to represent $\hat{Q}$, 
        which then acts on a state $\ket{\psi}$. 
    Instead, consider first that $\ket{\psi} = \ket{00}$, i.e. one of the basis vectors our transformation is to change:

    \begin{equation}
        \hat{Q}\ket{00} = \left(\ket{00} \bra{11} + \ket{11} \bra{00} + |10 \ra \bra{10} + \ket{01} \la 01|\right) \ \ket{00} 
    \end{equation}

    And as before, only the inner products of a vector with itself remains:
    \begin{equation}
        \begin{split}
            &= \ket{00} \la 11 \ket{00} + \ket{11} \la 00 \ket{00} + |10 \ra \la 10 \ket{00} + \ket{01} \la 01\ket{00} 
            \\ &= \ket{00} (0) + \ket{11} (1) + \ket{10} (0) + \ket{01} (0)
            \\ \Rightarrow & \hat{Q}\ket{00} = \ket{11} 
        \end{split}
    \end{equation}

    i.e the transformation has performed $\hat{Q}: \ket{00} \rightarrow \ket{11}$ as expected. 
    Then, if we apply the same transformation to a state which does not depend on one of the target states, eg,  
    \begin{equation}
        \begin{split}
            \ket{\psi} = & a \ket{10} + b \ket{01} 
            \\ \hat{Q}\ket{\psi} = & \bigg( \ket{00} \bra{11} + \ket{11} \bra{00} + |10 \ra \bra{10} + \ket{01} \la 01| \bigg) \bigg( a \ket{10} + b \ket{01} \bigg)
            \\ = &a \Big( \ket{00} \bra{11} \ket{10} + \ket{11} \bra{00}\ket{10} + |10 \ra \bra{10}\ket{10} + \ket{01} \la 01| \ket{10} \Big) 
            \\   &+ b \Big(\ket{00} \bra{11}\ket{01} + \ket{11} \la 00|\ket{01} + |10 \ra \bra{10}\ket{01} + \ket{01} \la 01|\ket{01}\Big) 
        \end{split}
    \end{equation}

    And since the inner product is a scalar, we can factor terms such as $\braket{11|10}$ to the beginning of expressions, eg $ \ket{00} \bra{11} \ket{10} = \la 11\ket{10} \ket{00}$, and we also know
    \begin{equation}
        \begin{split}
        \braket{11|10} = \braket{00|10} =  \braket{01|10} = \braket{11|01} = \braket{00|01}  = \braket{10|01} = 0 
        \\ \braket{10|10} = \braket{01|01} = 1 
        \end{split}
    \end{equation}
    We can express the above as 
    \begin{equation}
        \begin{split}
            \hat{Q}\ket{\psi} = 
            \ &a \Big((0) \ket{00}  + (0) \ket{11} + (1) \ket{10}  + (0) \ket{01} \Big)
            \\ + &b \Big((0)\ket{00} +(0) \ket{11}+ (0) \ket{10} + (1) |01 \ra \Big)
            \\ = &a\ket{10}| + b |01 \ra 
            \\ = &\ket{\psi}.
        \end{split}
    \end{equation}
    
    Then it is clear that, when $\ket{\psi}$ is a superposition of states unaffected by transformation $\hat{Q}$, then $\hat{Q}\ket{\psi} = \ket{\psi} $. 
\end{example}
\par 

This method generalises to systems with greater numbers of particles (qubits). 
If we briefly consider a 3 qubit system - and initialise all qubits in the standard basis state $\ket{0}$ 
- then the system is represented by $|000\ra = \ket{0} \otimes \ket{0} \otimes \ket{0} = \icol{0\\1} \otimes \icol{0\\1} \otimes \icol{0\\1}$. 
This quantity is an 8-row vector.  To calculate the outer product $\la 000 | 000 \ra$, we would be multiplying an 8-column bra $\la000| $ by an 8-row ket $|000\ra$. 
Clearly then we will be working with $8 \times 8$ matrices, which will become quite difficult to maintain effectively and efficiently quite fast. 
As we move to systems of larger size, standard matrix multiplication becomes impractical for hand-written analysis, 
    although of course remains tractable computationally up to $n\sim 10$ qubits. 
It is obvious that Dirac's bra/ket notation is a helpful, mathematically precise tool for \gls{qm}. 